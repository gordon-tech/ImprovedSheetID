{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Databases for each n-gram combination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 22 different n-gram combinations (1-3 grams) with maximum context 6. This notebook constructs a database for each type of n-gram and also a database storing the counts for each n-gram type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import dill\n",
    "from glob import iglob\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = 5\n",
    "combinations = []\n",
    "for n_gram in range(1, 4):\n",
    "    combinations += [[0] + list(tup) for tup in itertools.combinations(range(1, context), n_gram-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combinations = [\"\".join(str(num) for num in combination) for combination in combinations]\n",
    "len(combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '01', '02', '03', '012', '013', '023']\n"
     ]
    }
   ],
   "source": [
    "print(combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTotalBscore(bscore_file):\n",
    "    bscore_array = []\n",
    "    with open(bscore_file,'rb') as f:\n",
    "        bscore_array = pickle.load(f)\n",
    "    total_bscore = np.array([]).reshape(62,0)\n",
    "    for page in bscore_array:\n",
    "        try:\n",
    "            total_page = unpackbits(np.array(page), 62)\n",
    "        except TypeError:\n",
    "            total_page = np.array([]).reshape(62,0)\n",
    "            for num in page:\n",
    "                col = np.array(decodeColumn(num)).reshape(62,-1)\n",
    "                total_page = np.concatenate((total_page,col),axis=1)\n",
    "        total_bscore = np.concatenate((total_bscore,total_page),axis=1)\n",
    "    return total_bscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decodeColumn(num):\n",
    "    col = []\n",
    "    for i in range(62):\n",
    "        col.insert(0,num%2)\n",
    "        num = int(num/2)\n",
    "    return col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpackbits(x, num_bits):\n",
    "    xshape = list(x.shape)\n",
    "    x = x.reshape([-1, 1])\n",
    "    mask = 2**np.arange(num_bits, dtype=x.dtype).reshape([1, num_bits])\n",
    "    return np.flip((x & mask).astype(bool).astype(float), 1).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We precompute powers of 2 from $2^0$ to $2^{61}$ to speed up calculating hash values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "powers = 1 << np.arange(62)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_fps(data, combinations, dbs, piece):\n",
    "    for colindex in range(len(data)):\n",
    "        for combination in combinations:\n",
    "            cols = []\n",
    "            # we need at least enough fingerprints for all the indices in our combination\n",
    "            try:\n",
    "                for i in combination:\n",
    "                    cols.append(data[colindex+int(i)])\n",
    "            except IndexError:\n",
    "                continue\n",
    "            fp = []\n",
    "            equals_Zero = True\n",
    "            for column in cols:\n",
    "                hashint = int(column.dot(powers))\n",
    "                fp.append(hashint)\n",
    "                if hashint != 0:\n",
    "                    equals_Zero = False\n",
    "            if equals_Zero == True:\n",
    "                continue\n",
    "            dbs[combination][tuple(fp)][piece].append(colindex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we iterate over every query in our list of queries, compute the bootleg score for that query, generate all possible n-grams from the bootleg score, and store it in our database, which is an in-memory Python dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_DB(filelist, combinations, dbs = None):\n",
    "    if not dbs:\n",
    "        dbs = {combination: defaultdict(lambda : defaultdict(list)) for combination in combinations}\n",
    "    with open(filelist, 'r') as f:\n",
    "        failed = []\n",
    "        for i, curfile in enumerate(f):\n",
    "            curfile = curfile.strip().strip('\\n')\n",
    "            try:\n",
    "                num = curfile.split('/')[-1][0]\n",
    "                if num == 'd':\n",
    "                    data = getTotalBscore(curfile)\n",
    "                else:\n",
    "                    with open(curfile, 'rb') as pickle_file:\n",
    "                        data = pickle.load(pickle_file)\n",
    "                make_fps(data.T, combinations, dbs, i)\n",
    "            except:\n",
    "                failed.append(curfile)\n",
    "    return dbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_make_DB(filelist, combination):\n",
    "    dbs = {}\n",
    "    with open(filelist, \"r\") as f:\n",
    "        failed = []\n",
    "        for i, curfile in enumerate(f):\n",
    "            curfile = curfile.strip().strip('\\n')\n",
    "            try:\n",
    "                if curfile.split('/')[-1][0] == 'd':\n",
    "                    data = getTotalBscore(curfile)\n",
    "                else:\n",
    "                    with open(curfile, 'rb') as pickle_file:\n",
    "                        data = pickle.load(pickle_file)\n",
    "            except:\n",
    "                failed.append(curfile)\n",
    "            data = data.T\n",
    "            \n",
    "            for colindex in range(len(data)):\n",
    "                cols = []\n",
    "                try:\n",
    "                    for i in combination:\n",
    "                        cols.append(data[colindex+int(i)])\n",
    "                except IndexError:\n",
    "                    continue\n",
    "                fp = []\n",
    "                equals_Zero = True\n",
    "                for column in cols:\n",
    "                    hashint = int(column.dot(powers))\n",
    "                    fp.append(hashint)\n",
    "                    if hashint != 0:\n",
    "                        equals_Zero = False\n",
    "                if equals_Zero == True:\n",
    "                    continue\n",
    "                fp = tuple(fp)\n",
    "                if fp in dbs:\n",
    "                    if i in dbs[fp]:\n",
    "                        dbs[fp][i].append(colindex)\n",
    "                    else:\n",
    "                        dbs[fp][i] = [colindex]\n",
    "                else:\n",
    "                    dbs[fp] = {}\n",
    "                    dbs[fp][i] = [colindex]\n",
    "    return dbs\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_DB(db, combination, outdir):\n",
    "    with open(f\"{outdir}/{combination}.pkl\", \"wb\") as f:\n",
    "        dill.dump(db, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "filelist = 'cfg_files/db.list'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_dir = './data1/dyang/Marketplace_db'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(db_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We make a mapping from a number to each piece to save memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_to_piece = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(filelist, 'r') as f:\n",
    "    failed = []\n",
    "    for i, curfile in enumerate(f):\n",
    "        curfile = curfile.strip().strip('\\n')\n",
    "        piece = curfile.split('/')[-1][:-4]\n",
    "        num_to_piece[i] = piece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"num_to_piece_random.pkl\", \"wb\") as f:\n",
    "    pickle.dump(num_to_piece, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"num_to_piece_random.pkl\", 'rb') as f:\n",
    "    num_to_piece = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we create a database for each n-gram type (total 22). Each n-gram database maps from the n-gram (a tuple) to a dictionary. This dictionary maps each piece that the n-gram appears in to a list of offsets within the piece."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(8, len(combinations)):\n",
    "    dbs = make_DB(filelist, [combinations[i]])\n",
    "    store_DB(dbs[combinations[i]], combinations[i], db_dir)\n",
    "    dbs.clear()\n",
    "# for i in range(7, len(combinations)):\n",
    "#     dbs = new_make_DB(filelist, combinations[i])\n",
    "#     store_DB(dbs, combinations[i], db_dir)\n",
    "#     dbs.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbs = make_DB(filelist, [\"012\"])\n",
    "store_DB(dbs[\"012\"], \"012\", db_dir)\n",
    "dbs.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make fingerprint matches table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fingerprint matches table is a nested dictionary. \n",
    "* The first level maps each n-gram type to another dictionary. \n",
    "* The second dictionary maps each n-gram of that type to a tuple (x, y), where x is the total number of times the fingerprint occurs in IMSLP and y is the total number of PDFs in IMSLP with that fingerprint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_dir = 'data1/dyang/Marketplace_db'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_matches = {combination: {} for combination in ['024']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25598596/25598596 [01:47<00:00, 238391.37it/s]\n"
     ]
    }
   ],
   "source": [
    "# for combination in combinations:\n",
    "#     print(combination)\n",
    "#     with open(f\"{db_dir}/{combination}.pkl\", \"rb\") as f:\n",
    "#         d = dill.load(f)\n",
    "#     keys = list(d.keys())\n",
    "#     for fp in tqdm.tqdm(keys):\n",
    "#         # first element is number of times the fingerprint occurs, second element is number of PDFs containing the fingerprint\n",
    "#         fp_matches[combination][fp] = (sum(len(d[fp][piece]) for piece in d[fp]), len(d[fp]))\n",
    "#     d.clear()\n",
    "\n",
    "for combination in ['024']:\n",
    "    print(combination)\n",
    "    with open(f\"{db_dir}/{combination}.pkl\", \"rb\") as f:\n",
    "        d = dill.load(f)\n",
    "    keys = list(d.keys())\n",
    "    for fp in tqdm.tqdm(keys):\n",
    "        # first element is number of times the fingerprint occurs, second element is number of PDFs containing the fingerprint\n",
    "        a[combination][fp] = (sum(len(d[fp][piece]) for piece in d[fp]), len(d[fp]))\n",
    "    d.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['0', '01', '02', '03', '04', '012', '013'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp_matches.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#import dill\n",
    "fp_matches_file = f\"{db_dir}/fp_matches_3.pkl\"\n",
    "with open(fp_matches_file, \"wb\") as f:\n",
    "    pickle.dump(a, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7784183"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fp_matches['01'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['014', '023', '0', '01', '02', '03', '04', '012', '013'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('data1/dyang/Marketplace_db/fp_matches.pkl', 'rb') as f:\n",
    "    a = pickle.load(f)\n",
    "a.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "a['024'] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['014', '023', '0', '01', '02', '03', '04', '012', '013', '024'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24968078"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a['013'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickle.HIGHEST_PROTOCOL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4d95acae2008065a3680a55ac2020708dad7dcd0c8f61f74dfef49cf3110bf95"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('bootleg_score')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
